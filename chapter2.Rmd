# 2: Regression and model validation

> ### Instructions
> Describe the work you have done this week and summarize your learning.
>
> - Describe your work and results clearly. 
> - Assume the reader has an introductory course level understanding of > writing and reading R code as well as statistical methods.
> - Assume the reader has no previous knowledge of your data or the more advanced methods you are using.

## **DATA WRANGLING**

Sections 2.0--2.6 produce a dataset named `data/learning2014.csv`. For statistical analysis, skip to **section 2.7**.

**List of sections**

- 2.0 Packages
- 2.1 Reading data from the web
- 

### 2.0-- 2.6 Packages

Let's first load the required packages.

```{r}
# Packages
pacman::p_load(tidyverse, GGally, patchwork)

# Defining some custom functions
color_gender <- function () {scale_color_manual(values = rev(c("dodgerblue", "orangered")))}
fill_gender <- function () {scale_fill_manual(values = rev(c("dodgerblue", "orangered")))}

# Dark mode theme
backg <- "#141415"
theme_darkmode <- function(){
  ggdark::dark_theme_gray() %+replace% 
    ggplot2::theme(
      plot.background = element_rect(color = backg, fill = backg),
      legend.box.background = element_rect(fill = backg, color = backg),
      legend.background = element_rect(fill = backg, color = backg),
      panel.grid = element_line(color = "gray20")
    )
}

# Beautiful labels
make_labs <- function (data, var) {
  data %>%
    mutate(
      lab = case_when(
        .data[[var]] == "age" ~ "Age",
        .data[[var]] == "attitude" ~ "Attitude",
        .data[[var]] == "points" ~ "Exam points",
        .data[[var]] == "deep" ~ "Deep learning",
        .data[[var]] == "stra" ~ "Strategic learning",
        .data[[var]] == "surf" ~ "Surface learning",
      )
    ) %>%
    return()
}
```


Reading data from:

```{r}
# Get data
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep = "\t", header = TRUE)

# Check dimensions
dim(lrn14)
# str(lrn14)
```


### Observations from the data:

- Looks like the `lrn14` dataset has `r nrow(lrn14)` rows and `r ncol(lrn14)` columns.
- Most columns appear to be intergers, whereas only `gender` is character.


### 2.2 Scaling variables

> ### Instructions
> - Execute the example codes to see how vectorized division works
> - Use vector division to create a new column `attitude` in the `lrn14` data frame, where each observation of `Attitude` is scaled back to the original scale of the questions, by dividing it with the number of questions.
> 
> Hint:
> - Assign 'Attitude divided by 10' to the new column 'attitude.

```{r fig.width=7, fig.height=2}
# Scale the attitude variable to match other variables
lrn14 <- lrn14 %>%
  mutate(attitude = Attitude / 10)

# Check the distributions
ggpubr::ggarrange(
  # Density
  lrn14 %>% ggplot(aes(x = attitude)) + geom_density() +
    coord_cartesian(xlim = c(0, 6)),
  # Sina
  lrn14 %>%
    pivot_longer(
      cols = c(Attitude, attitude),
      names_to = "var",
      values_to = "value"
    ) %>% ggplot(aes(y = value, x = var)) +
    ggforce::geom_sina(size = .1, alpha = .5) +
    scale_y_sqrt() +
    geom_boxplot(width = .2, fill = NA, notch = T)
)
  
```


### 2.3 Combining variables

Computing row means for each class of questions in a for-loop.

> ### Instructions
> - Access the **dplyr** library
> - Execute the example codes to create the combination variables 'deep' and 'surf' as columns in `lrn14`
> - Select the columns related to strategic learning from `lrn14`
> - Create the combination variable 'stra' as a column in `lrn14`

> Hints:
> - Columns related to strategic learning are in the object `strategic_questions`. Use it for selecting the correct columns.
> - Use the function `rowMeans()` identically to the examples

```{r}
# Classify questions
deep <- c(
  "D03", "D11", "D19", "D27", "D07", "D14",
  "D22", "D30","D06",  "D15", "D23", "D31"
)
surf <- c(
  "SU02", "SU10", "SU18", "SU26", "SU05", "SU13",
  "SU21", "SU29", "SU08", "SU16", "SU24", "SU32"
)
stra <- c(
  "ST01", "ST09", "ST17", "ST25",
  "ST04", "ST12", "ST20", "ST28"
)

# Compute averages in a loop
for (Qclass in c("deep", "surf", "stra")) {
  lrn14[[Qclass]] <- rowMeans(lrn14[, get(Qclass)])
}

# Same thing, without creating new objects in the environment
# lrn14 <- lrn14 %>%
#   rowwise() %>%
#   mutate(
#     deep = mean(c( # Deep questions
#       D03, D11, D19, D27, D07, D14, D22, D30, D06, D15, D23, D31
#     )),
#     surf = mean(c( # Surface questions
#       SU02, SU10, SU18, SU26, SU05, SU13, SU21, SU29, SU08, SU16, SU24, SU32
#     )),
#     stra = mean(c( # Strategic questions
#       ST01, ST09, ST17, ST25, ST04, ST12, ST20, ST28
#     ))
#   ) %>% ungroup()
```


### 2.4 Selecting columns

Dropping individual question data and only keeping variables relevant for the analysis.

> ### Instructions
> - Access the **dplyr** library
> - Create object `keep_columns`
> - Use `select()` (possibly together with `one_of()`) to create a new data frame `learning2014` with the columns named in `keep_columns`.
> - Look at the structure of the new dataset
> 
> Hint:
> - See the previous exercise or the data wrangling cheatsheet for help on how to select columns

```{r}
# Pick relevant vars
keep_columns <- c(
  "gender",
  "Age",
  "attitude",
  "deep",
  "stra",
  "surf",
  "Points"
)

# Drop useless vars
learning2014 <- lrn14 %>% select(
  all_of(keep_columns)
)

# See structure
str(learning2014)
```


### 2.5 Modifying column names

Changing all column names to include only lowercase letters.

```{r}
old_colnames <- colnames(learning2014)
learning2014 <- learning2014 %>%
  rename("age" = Age, "points" = Points)
new_colnames <- colnames(learning2014)

data.frame(old_colnames, new_colnames) %>% knitr::kable()
```


### 2.6 Excluding observations

Excluding students that did not attend the exam.

```{r}
# Filter non-attending students
learning2014 <- learning2014 %>%
  filter(points > 0)
```


### Write to file

Saving the processed minimal dataframe as a `.csv` file.

```{r}
# Write
readr::write_csv(learning2014, "data/learning2014.csv")
```

*** 

## **ANALYSIS**

## Get data

> ### Instructions
> Read the students2014 data into R either from your local folder (if you completed the Data wrangling part) or from this url: https://raw.githubusercontent.com/KimmoVehkalahti/Helsinki-Open-Data-Science/master/datasets/learning2014.txt . (The separator is a comma "," and the file includes a header). Explore the structure and the dimensions of the data and describe the dataset briefly, assuming the reader has no previous knowledge of it. There is information related to the data here. (0-2 points)

Let's read in the `students2014.csv` dataset and check that it is read correctly.

```{r fig.width=7, fig.height=2}
# Get data
data <- readr::read_csv("data/learning2014.csv", show_col_types = F)

# Glance at the data
# data %>% head() %>% knitr::kable()
str(data)

# Plot data missingness
naniar::vis_miss(data) + theme_darkmode() + ggtitle("Missingness map")
```

There are a total of **166 observations** and **7 variables**. We are dealing with **complete data** with no missing values. To note, there is no subject identifier. These may not be needed as we do not have repeated measures. The variables can be divided to the types below. Click here for more comprehensive [metadata](http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-meta.txt).

#### Population characteristics

- `age`: Age of the participant (in years) derived from the date of birth.
- `gender`: Here gender is coded as a nominal variable with two defined/prevalent values (F = Female, M = Male).


#### Survey answers

Clearly, the four variables `attitude`, `deep`, `stra`, and `surf` represent survey answers on a likert scale (1--5). `attitude` captures student's global attitude towards statistics. The rest of the variables were computed as averages of various interrelated questions and describe the traits below and also described in detail e.g., [here](https://spark.scu.edu.au/kb/tl/teach/focus-on-learning/deep-surface-and-strategic-learning). These traits are important as they may influence success in students' work, reflected by exam `points`.

- `surf`: *Surface learning*; emphasis upon memorising details to complete the assignment. Learning may be more superficial.
- `deep`: *Deep learning*; looking for the overall meaning and attempting to process information in a holistic way.
- `stra`: *Strategic learning*; organizing one's learning with the objective of achieving a positive outcome. Can involve a combination of both deep and surface learning strategies.


#### Exam results

- `points`: Results of the statistics exam. I did not find the maximum possible value from the metadata. Before the analysis, students that did not attend the exam (points == 0) were excluded from the dataset.


### Summaries

Let's summarize the numerical variables. 

```{r}
# Summaries for numeric variables
do.call(cbind, lapply(data, summary)) %>%
  data.frame() %>% select(-gender) %>%
  mutate(across(1:6, \(x) as.numeric(x))) %>%
  mutate(across(1:6, \(x) round(x, 1))) %>%
  t() %>% knitr::kable() # DT::datatable()
```

Let's also see the distribution of `gender`. Later we'll probably also see whether `gender` modifies the relationship between `attitude`/learning and exam `points`.

```{r}
data %>% count(gender) %>%
  mutate(pct = scales::percent(n / sum(n))) %>%
  knitr::kable()
```





## 2.7 Visualizations with `ggplot2`

> ### Instructions
> Show a graphical overview of the data and show summaries of the variables in the data. Describe and interpret the outputs, commenting on the distributions of the variables and the relationships between them. (0-3 points)


### Distributions

Let's begin by visually inspecting the distributions of our dataset.

```{r fig.height=4, fig.width=7, message=FALSE, warning=FALSE}
p <- data %>% pivot_longer(
  cols = colnames(data)[-1],
  values_to = "value",
  names_to = "var"
) %>%
  make_labs(data = ., var = "var") %>%
  ggplot(aes(x = value, color = lab, fill = lab, y = lab, linetype = gender))
p <- p + ggridges::geom_density_ridges(
  rel_min_height = .001, quantile_lines = T, quantiles = .5,
  jittered_points = TRUE, position = "raincloud",
  point_alpha = .5, point_size = 1, alpha = .3
)

breakx <- c(1, 5, seq(10, 60, by = 10))
p <- p + scale_x_sqrt(breaks = breakx, labels = breakx)
p <- p + labs(
  title = "Distributions by gender",
  subtitle = "(On a square root x-axis)"
) + xlab("Value") + ylab("")
p
```

**Likert-scale variables** are quite evenly spread on the range of 1--5. It appears that these students are `deep` learners more so than surface learners (`surf`). By visual inspection, men have more positive `attitude` towards statistics than women. Students tend to be of quite **young** `age` although a few older students skew the distribution heavily to the right. It also seems like men may be slightly older than female students. Whether these differences are statistically significant would require further testing...


### Predictors of exam `points`

It is plausibile that students' `attitude` or learning strategies influence exam `points`. Therefore, let's glance over these potential relationships:

```{r fig.width=7, fig.height=4}
p <- data %>% pivot_longer(
  cols = c(attitude, deep, stra, surf),
  values_to = "answer",
  names_to = "var"
) %>%
  make_labs(var = "var") %>%
  ggplot(aes(x = answer, y = points, color = lab))
p <- p + geom_point(alpha = .5, size = .5)
p <- p + geom_smooth(method = "lm", se = F)
p <- p + coord_cartesian(xlim = c(1, 5))
p <- p + labs(title = "Potential predictors for good or bad exam success") +
  xlab("Average answer for the set of questions") + ylab("Exam points")
p
```

Interestingly, `attitude` shows positive relationship with exam `points`, whereas `surf`ace learning may be negatively associated with `points`. 


### Gender differences

It could be hypothesized that attitude, learning strategies and/or exam points differ between the `gender`s. Let's also do some preliminary hypothesis testing using Wilcoxon signed-ranks test that requires minimal assumptions.

```{r fig.height=4, fig.width=8, message=FALSE, warning=FALSE}
# Gender bar plot
plotdata <- data %>%
  group_by(gender) %>%
  reframe(n = n()) %>%
  mutate(
    pct = scales::percent(n / sum(n))
  )
# Calculate 95% CIs
for (i in 1:nrow(plotdata)) {
  plotdata$Lower[i] <-
    Hmisc::binconf(x = plotdata$n[i], n = sum(plotdata$n))[[2]] *
    sum(plotdata$n)
  plotdata$Upper[i] <-
    Hmisc::binconf(x = plotdata$n[i], n = sum(plotdata$n))[[3]] *
    sum(plotdata$n)
}
# Plot
p <- plotdata %>%
  ggplot(aes(x = gender, y = n, fill = gender))
p <- p + geom_col(width = .5)
p <- p + geom_errorbar(width = .1, aes(ymin = Lower, ymax = Upper))
p <- p + geom_text(aes(y = Upper, label = paste0(pct, "\n")))
p <- p + fill_gender()
p <- p + scale_y_continuous(expand = expansion(mult = c(0, .1)))
p <- p + labs(title = "Gender", subtitle = "95% CI")
p1 <- p

# Facetted sina plots
p <- data %>% pivot_longer(
  cols = colnames(data)[-1],
  values_to = "value",
  names_to = "var"
) %>%
  make_labs(var = "var") %>%
  ggplot(aes(y = value, x = gender, color = gender))
p <- p + geom_violin(fill = "white", color = NA, alpha = .1)
p <- p + ggforce::geom_sina(size = .5)
p <- p + geom_boxplot(width = .2, color = "white", outlier.color = NA, alpha = .5)
p <- p + stat_summary(fun = mean, shape = 4, color = "white")
p <- p + facet_wrap(. ~ lab, scales = "free")
p <- p + color_gender()
p <- p + labs(
  title = "Potential gender differences",
  subtitle = "Wilcoxon signed-ranks test"
)
p <- p + ggpubr::stat_compare_means(
  method = "wilcox.test", size = 3,
  label = "p.format", hjust = .5, aes(x = 1.5)
)
p <- p + scale_y_continuous(expand = expansion(mult = c(0, .15)))
p2 <- p

ggpubr::ggarrange(p1, p2, legend = "none", widths = c(.3, 1), labels = "AUTO")
```

As observed from the plots, 

### Influence of gender (learning × gender interactions)

Perhaps `gender` modifies the relationship between learning strategies and exam points. 

```{r fig.width=5, fig.height=3}
p <- data %>%
  ggplot(aes(x = attitude, y = points, col = gender))
p <- p + geom_point()
p <- p + geom_smooth(method = "lm")
p <- p + ggtitle("Student's attitude versus exam points")
p <- p + coord_cartesian(xlim = c(1, 5))
p <- p + color_gender()
p
```


```{r message=FALSE}
# Visualize
# pairs(data[-1])
data %>% GGally::ggpairs(
  aes(col = gender, alpha = .3),
  lower = list(continuous = "smooth")
) +
  color_gender() + fill_gender()

```


## 2.8 Exploring a data frame

## 2.9 Simple regression

## 2.10 Multiple regression

## 2.11 Graphical model validation

## 2.12 Making predictions
