# 2: Regression and model validation

> ### Instructions
> Describe the work you have done this week and summarize your learning.
>
> - Describe your work and results clearly. 
> - Assume the reader has an introductory course level understanding of writing and reading R code as well as statistical methods.
> - Assume the reader has no previous knowledge of your data or the more advanced methods you are using.

## **DATA WRANGLING**

Sections 2.0--2.6 produce a dataset named `data/learning2014.csv`. For statistical analysis, **skip to section 2.7**.

**List of sections**

- 2.0 Packages
- 2.1 Reading data from the web
- 2.2 Scaling variables
- 2.3 Combining variables
- 2.4 Selecting columns
- 2.5 Modifying column names
- 2.6 Excluding observations

### 2.1 Packages and functions

Let's first load the required packages and define some custom functions.

```{r}
# Packages
pacman::p_load(tidyverse, GGally, patchwork)

# Defining some custom functions
color_gender <- function () {scale_color_manual(values = rev(c("dodgerblue", "orangered")))}
fill_gender <- function () {scale_fill_manual(values = rev(c("dodgerblue", "orangered")))}

# Dark mode theme
backg <- "#141415"
theme_darkmode <- function(){
  ggdark::dark_theme_gray() %+replace% 
    ggplot2::theme(
      plot.background = element_rect(color = backg, fill = backg),
      legend.box.background = element_rect(fill = backg, color = backg),
      legend.background = element_rect(fill = backg, color = backg),
      panel.grid = element_line(color = "gray20")
    )
}

# Beautiful labels
make_labs <- function (data, var) {
  data %>% mutate(lab = case_when(
    .data[[var]] == "age" ~ "Age",
    .data[[var]] == "attitude" ~ "Attitude",
    .data[[var]] == "points" ~ "Exam points",
    .data[[var]] == "deep" ~ "Deep learning",
    .data[[var]] == "stra" ~ "Strategic learning",
    .data[[var]] == "surf" ~ "Surface learning",
  )) %>% return()
}
```


Reading data from:

```{r}
# Get data
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep = "\t", header = TRUE)

# Check dimensions
dim(lrn14)
# str(lrn14)
```


- Looks like the `lrn14` dataset has `r nrow(lrn14)` rows and `r ncol(lrn14)` columns.
- Most columns appear to be intergers, whereas only `gender` is character.


### 2.2 Scaling variables

Returning variable `Attitude` to its original scale between 1--5 (likert scale).

```{r fig.width=7, fig.height=2}
# Scale the attitude variable to match other variables
lrn14 <- lrn14 %>%
  mutate(attitude = Attitude / 10)

# Check the distributions
# ggpubr::ggarrange(
#   # Density
#   lrn14 %>% ggplot(aes(x = attitude)) + geom_density() +
#     coord_cartesian(xlim = c(0, 6)),
#   # Sina
#   lrn14 %>%
#     pivot_longer(
#       cols = c(Attitude, attitude),
#       names_to = "var",
#       values_to = "value"
#     ) %>% ggplot(aes(y = value, x = var)) +
#     ggforce::geom_sina(size = .1, alpha = .5) +
#     scale_y_sqrt() +
#     geom_boxplot(width = .2, fill = NA, notch = T)
# )
```


### 2.3 Combining variables

Computing row means for each class of questions in a for-loop.

```{r}
# Classify questions
deep <- c(
  "D03", "D11", "D19", "D27", "D07", "D14",
  "D22", "D30","D06",  "D15", "D23", "D31"
)
surf <- c(
  "SU02", "SU10", "SU18", "SU26", "SU05", "SU13",
  "SU21", "SU29", "SU08", "SU16", "SU24", "SU32"
)
stra <- c(
  "ST01", "ST09", "ST17", "ST25",
  "ST04", "ST12", "ST20", "ST28"
)

# Compute averages in a loop
for (Qclass in c("deep", "surf", "stra")) {
  lrn14[[Qclass]] <- rowMeans(lrn14[, get(Qclass)])
}
```


### 2.4 Selecting columns

Dropping individual question data and only keeping variables relevant for the analysis.

```{r}
# Pick relevant vars
keep_columns <- c("gender", "Age", "attitude", "deep", "stra", "surf", "Points")

# Drop useless vars
learning2014 <- lrn14[, keep_columns]

# See structure
str(learning2014)
```


### 2.5 Modifying column names

Harmonizing all column names to include only lowercase letters.

```{r}
# old_colnames <- colnames(learning2014)
learning2014 <- learning2014 %>%
  rename("age" = Age, "points" = Points)
# new_colnames <- colnames(learning2014)
# data.frame(old_colnames, new_colnames) %>% knitr::kable()
```


### 2.6 Excluding observations

Excluding students that did not attend the exam.

```{r}
# Filter non-attending students
learning2014 <- learning2014 %>%
  filter(points > 0)
```


### Write to file

Saving the processed minimal dataframe as a `.csv` file.

```{r}
# Write
readr::write_csv(learning2014, "data/learning2014.csv")
```

*** 

## **ANALYSIS**

This part describes the statistical analysis of `learning2014` dataset.

### Get data

Let's read in the `learning2014.csv` dataset and check that it is read correctly.

```{r fig.width=7, fig.height=2}
# Read data
data <- readr::read_csv("data/learning2014.csv", show_col_types = F)

# Glance at the data
# data %>% head() %>% knitr::kable()
str(data, give.attr = F)

# Plot data missingness
naniar::vis_miss(data) + theme_darkmode() + ggtitle("Missingness map")
```

There are a total of **166 observations** and **7 variables**. We are dealing with **complete data** with no missing values. The variables can be divided to the types below (click here for more comprehensive [metadata](http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-meta.txt)).

#### Population characteristics

- `age`: Age of the participant (in years) derived from the date of birth.
- `gender`: Here gender is coded as a nominal variable with two defined/prevalent values (F = Female, M = Male).


#### Survey answers

Clearly, the four variables `attitude`, `deep`, `stra`, and `surf` represent survey answers on a likert scale (1--5). `attitude` captures student's global attitude towards statistics. The rest of the variables were computed as averages of various interrelated questions and describe the traits below and also described in detail e.g., [here](https://spark.scu.edu.au/kb/tl/teach/focus-on-learning/deep-surface-and-strategic-learning). These traits are important as they may influence success in students' work, reflected by exam `points`.

- `surf`: *Surface learning*; emphasis upon memorising details to complete the assignment. Learning may be more superficial.
- `deep`: *Deep learning*; looking for the overall meaning and attempting to process information in a holistic way.
- `stra`: *Strategic learning*; organizing one's learning with the objective of achieving a positive outcome. Can involve a combination of both deep and surface learning strategies.


#### Exam results

- `points`: Results of the statistics exam. I did not find the maximum possible value from the metadata. Before the analysis, students that did not attend the exam (points == 0) were excluded from the dataset.

To note, these data lack subject identifier (ID) variable. However, it may not be needed as we do not have repeated measures. 


### Summaries

Let's summarize the numerical variables. 

```{r}
# Summaries for numeric variables
do.call(cbind, lapply(data, summary)) %>%
  data.frame() %>% select(-gender) %>%
  mutate(across(1:6, \(x) as.numeric(x))) %>%
  mutate(across(1:6, \(x) round(x, 1))) %>%
  t() %>% knitr::kable() # DT::datatable()
```

Let's also see the distribution of `gender`. It appears that most students (66%) are female. On average, male students are `r round(mean(data$age[which(data$gender == "M")]) - mean(data$age[which(data$gender == "F")]), 1)` older than female students. Later we'll probably also see whether `gender` modifies the relationship between `attitude`/learning and exam `points`.

```{r}
data %>% group_by(gender) %>%
  summarise(
    n = sum(!is.na(gender)),
    age_mean_sd = paste0(round(mean(age), 1), " (", round(sd(age), 1), ")")
  ) %>%
  mutate(pct = scales::percent(n / sum(n))) %>%
  select(gender, n, pct, everything()) %>%
  knitr::kable()
```





## 2.7 Visualizations with `ggplot2`

> ### Instructions
> Show a graphical overview of the data and show summaries of the variables in the data. Describe and interpret the outputs, commenting on the distributions of the variables and the relationships between them. (0-3 points)


### Distributions

Let's begin by visually inspecting the distributions of our dataset.

```{r fig.height=4, fig.width=7, message=FALSE, warning=FALSE}
p <- data %>% pivot_longer(
  cols = colnames(data)[-1],
  values_to = "value",
  names_to = "var"
) %>%
  make_labs(data = ., var = "var") %>%
  ggplot(aes(x = value, color = lab, fill = lab, y = lab, linetype = gender))
p <- p + ggridges::geom_density_ridges(
  aes(point_shape = gender),
  rel_min_height = .001, quantile_lines = T, quantiles = .5,
  jittered_points = TRUE, position = "raincloud",
  point_alpha = .5, point_size = 2, alpha = .3
)
p <- p + scale_shape_manual(values = c(0, 2))

breakx <- c(1, 5, seq(10, 60, by = 10))
p <- p + scale_x_sqrt(breaks = breakx, labels = breakx)
p <- p + labs(
  title = "Distributions by gender",
  subtitle = "(On a square root x-axis)"
) + xlab("Value") + ylab("")
p
```

**Likert-scale variables** are quite evenly spread on the range of 1--5. It appears that these students are `deep` learners more so than surface learners (`surf`). By visual inspection, men have more positive `attitude` towards statistics than women. Students tend to be of quite **young** `age` although a few older students skew the distribution heavily to the right. It also seems like men may be slightly older than female students. Whether these differences are statistically significant would require further testing...


### Predictors of exam `points`

It is plausibile that students' `attitude` or learning strategies influence exam `points`. Therefore, let's glance over these potential relationships:

```{r fig.width=7, fig.height=4}
p <- data %>% pivot_longer(
  cols = c(attitude, deep, stra, surf),
  values_to = "answer",
  names_to = "var"
) %>%
  make_labs(var = "var") %>%
  ggplot(aes(x = answer, y = points, color = lab))
p <- p + geom_point(alpha = .5, size = .5)
p <- p + geom_smooth(method = "lm", se = F)
p <- p + coord_cartesian(xlim = c(1, 5))
p <- p + labs(title = "Potential predictors for good or bad exam success") +
  xlab("Average answer for the set of questions") + ylab("Exam points")
p
```

Intuitively and as hypothesized, `attitude` shows positive relationship with exam `points`, whereas `surf`ace learning may be negatively associated with `points`. The first does not however imply that attitude is *causal* for success, as there could be a confounder (e.g., competence) that associates with attitude and *causes* good exam points. The link between surface learning and poor exam points is surprising, as surface learning is focused precisely around the exam. However, whether these associations are statistically significant requires testing!


### Gender differences

It could be hypothesized that attitude, learning strategies and/or exam points differ between the `gender`s. Let's also do some preliminary hypothesis testing using Wilcoxon signed-ranks test that requires minimal assumptions.

```{r fig.height=4, fig.width=8, message=FALSE, warning=FALSE}
# Gender bar plot
plotdata <- data %>%
  group_by(gender) %>%
  reframe(n = n()) %>%
  mutate(
    pct = scales::percent(n / sum(n))
  )
# Calculate 95% CIs
for (i in 1:nrow(plotdata)) {
  plotdata$Lower[i] <- Hmisc::binconf(
    x = plotdata$n[i], n = sum(plotdata$n)
  )[[2]] * sum(plotdata$n)
  plotdata$Upper[i] <- Hmisc::binconf(
    x = plotdata$n[i], n = sum(plotdata$n)
  )[[3]] * sum(plotdata$n)
}
# Plot
p <- plotdata %>%
  ggplot(aes(x = gender, y = n, fill = gender))
p <- p + geom_col(width = .5)
p <- p + geom_errorbar(width = .2, aes(ymin = Lower, ymax = Upper))
p <- p + geom_text(aes(y = Upper, label = paste0(pct, "\n")))
p <- p + fill_gender()
p <- p + scale_y_continuous(expand = expansion(mult = c(0, .1)))
p <- p + labs(title = "Gender", subtitle = "95% CI")
p1 <- p

# Facetted sina plots
p <- data %>% pivot_longer(
  cols = colnames(data)[-1],
  values_to = "value",
  names_to = "var"
) %>%
  make_labs(var = "var") %>%
  ggplot(aes(y = value, x = gender, color = gender))
p <- p + geom_violin(fill = "white", color = NA, alpha = .1)
p <- p + ggforce::geom_sina(size = .5)
p <- p + geom_boxplot(width = .2, color = "white", outlier.color = NA, alpha = .5)
p <- p + stat_summary(fun = mean, shape = 4, color = "white")
p <- p + facet_wrap(. ~ lab, scales = "free")
p <- p + color_gender()
p <- p + labs(
  title = "Potential gender differences",
  subtitle = "Wilcoxon signed-ranks test"
)
p <- p + ggpubr::stat_compare_means(
  method = "wilcox.test", size = 3,
  label = "p.format", hjust = .5, aes(x = 1.5)
)
p <- p + scale_y_continuous(expand = expansion(mult = c(0, .15)))
p2 <- p

ggpubr::ggarrange(p1, p2, legend = "none", widths = c(.3, 1), labels = "AUTO")
```

As observed from the plots, male students are the minority on the course and they are significantly older than female students. Men have significantly more positive attitude on statistics. Strategic learning does not differ between genders despite quite small $p$ value.


### Influence of gender (interactions)

Perhaps `gender` modifies the relationship between learning strategies and exam points -- let's entertain this idea. 

```{r fig.height=6, fig.width=10, message=FALSE}
# Define independent variables
traits <- tribble(
  ~var, ~lab, ~unit, ~zoomx,
  "age", "age", "Years", c(10, 60),
  "attitude", "attitude", "Averaged answer", c(1, 5),
  "deep", "deep learning", "Averaged answer", c(1, 5),
  "stra", "strategic learning", "Averaged answer", c(1, 5),
  "surf", "surface learning", "Averaged answer", c(1, 5)
)

# Plot in a loop
plist <- lapply(1:nrow(traits), function (i) {
  p <- data %>%
    ggplot(aes(x = .data[[traits$var[i]]], y = points, col = gender, fill = gender))
  p <- p + geom_point(size = .5, alpha = .5)
  p <- p + geom_smooth(method = "lm")
  p <- p + ggtitle(paste0("Student's ", traits$lab[[i]], "\nversus exam points"))
  p <- p + coord_cartesian(xlim = traits$zoomx[[i]])
  p <- p + xlab(traits$unit[[i]]) + ylab("Exam points")
  p <- p + color_gender() + fill_gender()
  p
})
# Combine plots into a panel
plist[[1]] + plist[[2]] + plist[[3]] + plist[[4]] + plist[[5]] +
  plot_layout(guides = "collect")
```

The slopes for men and women seem quite similar. If anything, aging might hinder men's exam success, whereas women do not experience age-related decline in exam points.

Finally, lets make a "monster plot" of all the relationships within the data.

```{r message=FALSE}
# Visualize
# pairs(data[-1])
data %>% GGally::ggpairs(
  aes(col = gender, alpha = .3),
  lower = list(continuous = "smooth")
) +
  color_gender() + fill_gender()

```

Here it is demonstrated that the strongest correlation is observed between `attitude` and `points`. In men, there is a strong inverse correlation between surface and deep learning, whereas such phenomenon doesn't exist in women. This implies that women may employ both strategies simultaneously, whereas in men these two strategies may be mutually exclusive. 


## 2.8 Exploring a data frame



## 2.9 Simple regression

## 2.10 Multiple regression

## 2.11 Graphical model validation

## 2.12 Making predictions
