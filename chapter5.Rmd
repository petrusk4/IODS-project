# 5 Dimensionality reduction techniques
## Setup

First let's load the needed packages and some custom functions.

```{r}
# Packages
pacman::p_load(tidyverse)

# Custom functions
source("src/fig_setup.R")

# Run time
start.time <- Sys.time()
```


## 5.0 Get data

Save the data to an object and check its structure

```{r message=FALSE, warning=FALSE}
# Read the most up-to-date data
datasets <- list.files("data/human/ready", full.names = T)
newest <- datasets %>% sub('.*_', '', .) %>% as.Date() %>% max()
data <- datasets[grepl(newest, datasets)] %>%
  readr::read_csv(show_col_types = F) %>%
  column_to_rownames("Country")

# Glance at the data
finalfit::finalfit_glimpse(data)$Continuous %>%
  select(-label) %>%
  knitr::kable()

# Visualize
GGally::ggpairs(data)
```


## PCA
### Using raw values

```{r}
# Principal component analysis
PCA <- prcomp(data, center = F, scale. = F)
PCA_s <- summary(PCA)
importances <- scales::percent(PCA_s$importance[2, ], .01)

# Plot
p <- ggbiplot::ggbiplot(
  PCA, #obs.scale = 0, var.scale = 0, 
  # groups = rownames(PCA), ellipse = TRUE, circle = TRUE
) + ggtitle("GNI in PC1 explains all variance")

# Print without white edges
grid::grid.newpage()
grid::grid.draw(grid::rectGrob(gp = grid::gpar(fill = backg)))
print(p, newpage = FALSE)
```

Because the variables have differing scales, now the GNI that is loaded in PC1 explains all the variability. This is not OK and we have to standardize the data asap. 


### Using Standardized values

```{r}
data_z <- scale(data) %>% data.frame()

# Principal component analysis
PCA <- prcomp(data_z, center = F, scale. = F)
PCA_s <- summary(PCA)
importances <- scales::percent(PCA_s$importance[2, ], .01)

# Plot
p <- ggbiplot::ggbiplot(
  PCA, #obs.scale = 0, var.scale = 0, 
  # groups = rownames(PCA), ellipse = TRUE, circle = TRUE
) + ggtitle("Variables are now balanced")

# Print without white edges
grid::grid.newpage()
grid::grid.draw(grid::rectGrob(gp = grid::gpar(fill = backg)))
print(p, newpage = FALSE)
```

As expected, results are much more balanced when variables are now measured at the same scale. Most influential variables include `Labo.FMm` `Mar.Mor` and `Ado.Birth`.


### Personal interpretation

The 2nd PC shown above explains 16% of the variability in the data which is a good number. As always, most is explained by PC1 (54% here). Education and expected life span have negative loadings for the 1st PC. Maternal mortality and adolescent birth rate have positive loadings. These negatively and positively loaded variables have inverse correlation in the dataset, e.g., `Mat.Mor` and `Edu.Exp`: $r=0.7$.


## MCA

```{r fig.width=10, fig.height=10}
# Get data
tea <- read.csv("https://raw.githubusercontent.com/KimmoVehkalahti/Helsinki-Open-Data-Science/master/datasets/tea.csv", stringsAsFactors = TRUE)
glimpse(tea)#; View(tea) 

# Visualize
tea %>%
  gather() %>%
  ggplot(aes(value)) +
  facet_wrap("key", scales = "free", ncol = 8) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +
  ggtitle('Visualization of the "tea" data set')
```


```{r}
# Drop problematic variable
names(tea)[19] # Age
mca <- FactoMineR::MCA(tea[, -which(names(tea) == "age")], graph = FALSE)
summary(mca)

```

```{r}
factoextra::fviz_screeplot(
  mca, addlabels = TRUE, ylim = c(0, 20)
) +
  theme_darkmode()
```



```{r}
# Plot
plot(mca, invisible = c("ind"), habillage = "quali", graph.type = "classic")
```






